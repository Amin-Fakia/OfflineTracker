{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sup_fakiaa\\Anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from shutil import copyfile\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from ipywidgets import interact, widgets\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_rotated_ellipse_ransac(data,iter=50,sample_num=10,offset=80.0):\n",
    "\n",
    "    count_max = 0\n",
    "    effective_sample = None\n",
    "\n",
    "    for i in range(iter):\n",
    "        sample = np.random.choice(len(data), sample_num, replace=False)\n",
    "\n",
    "        xs = data[sample][:,0].reshape(-1,1)\n",
    "        ys = data[sample][:,1].reshape(-1,1)\n",
    "\n",
    "        J = np.mat( np.hstack((xs*ys,ys**2,xs, ys, np.ones_like(xs,dtype=np.float64))) )\n",
    "        Y = np.mat(-1*xs**2)\n",
    "        P= (J.T * J).I * J.T * Y\n",
    "\n",
    "        # fitter a*x**2 + b*x*y + c*y**2 + d*x + e*y + f = 0\n",
    "        a = 1.0; b= P[0,0]; c= P[1,0]; d = P[2,0]; e= P[3,0]; f=P[4,0];\n",
    "        ellipse_model = lambda x,y : a*x**2 + b*x*y + c*y**2 + d*x + e*y + f\n",
    "\n",
    "        # threshold \n",
    "        ran_sample = np.array([[x,y] for (x,y) in data if np.abs(ellipse_model(x,y)) < offset ])\n",
    "\n",
    "        if(len(ran_sample) > count_max):\n",
    "            count_max = len(ran_sample) \n",
    "            effective_sample = ran_sample\n",
    "\n",
    "    return fit_rotated_ellipse(effective_sample)\n",
    "\n",
    "\n",
    "def fit_rotated_ellipse(data):\n",
    "\n",
    "    xs = data[:,0].reshape(-1,1) \n",
    "    ys = data[:,1].reshape(-1,1)\n",
    "\n",
    "    J = np.mat( np.hstack((xs*ys,ys**2,xs, ys, np.ones_like(xs,dtype=np.float64))) )\n",
    "    Y = np.mat(-1*xs**2)\n",
    "    P= (J.T * J).I * J.T * Y\n",
    "\n",
    "    a = 1.0; b= P[0,0]; c= P[1,0]; d = P[2,0]; e= P[3,0]; f=P[4,0];\n",
    "    theta = 0.5* np.arctan(b/(a-c))  \n",
    "    \n",
    "    cx = (2*c*d - b*e)/(b**2-4*a*c)\n",
    "    cy = (2*a*e - b*d)/(b**2-4*a*c)\n",
    "\n",
    "    cu = a*cx**2 + b*cx*cy + c*cy**2 -f\n",
    "    w= np.sqrt(cu/(a*np.cos(theta)**2 + b* np.cos(theta)*np.sin(theta) + c*np.sin(theta)**2))\n",
    "    h= np.sqrt(cu/(a*np.sin(theta)**2 - b* np.cos(theta)*np.sin(theta) + c*np.cos(theta)**2))\n",
    "\n",
    "    ellipse_model = lambda x,y : a*x**2 + b*x*y + c*y**2 + d*x + e*y + f\n",
    "\n",
    "    error_sum = np.sum([ellipse_model(x,y) for x,y in data])\n",
    "    print('fitting error = %.3f' % (error_sum))\n",
    "\n",
    "    return (cx,cy,w,h,theta)\n",
    "\n",
    "def apply_blur(image, blur_amount=5):\n",
    "    return cv2.GaussianBlur(image, (blur_amount, blur_amount), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitPupil(image,circ_thresh=0.5,thresh_val=60,kernel=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3)),min_thresh=170,max_thresh=280,resize=1):\n",
    "        #print(image)\n",
    "        \n",
    "        temp_image = image.copy()\n",
    "        \n",
    "\n",
    "        inf_img = temp_image.copy()\n",
    "        \n",
    "        image_gray = cv2.cvtColor(temp_image , cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(image_gray,(3,3),0)\n",
    "        \n",
    "        ret,thresh1 = cv2.threshold(blur,thresh_val,255,cv2.THRESH_BINARY)\n",
    "        \n",
    "        opening = cv2.morphologyEx(thresh1, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        \n",
    "        #size_el = 0\n",
    "        temp_image  = 255 - closing\n",
    "        \n",
    "        \n",
    "        contours, hierarchy = cv2.findContours(temp_image , cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        hull = []\n",
    "        for i in range(len(contours)):\n",
    "          hull.append(cv2.convexHull(contours[i], False)) \n",
    "        \n",
    "        cx,cy,w,h,theta = 0.0,0.0,0.0,0.0,0.0\n",
    "        for con in hull:\n",
    "            \n",
    "            approx = cv2.approxPolyDP(con, 0.01 * cv2.arcLength(con,True),True)\n",
    "            area = cv2.contourArea(con)\n",
    "            perimeter = cv2.arcLength(con, True)\n",
    "            circularity = 4 * np.pi * (area / (perimeter * perimeter))\n",
    "\n",
    "\n",
    "            if circularity > circ_thresh:\n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "                if(len(approx) > 10 and area > 70):\n",
    "                        try:\n",
    "                        \n",
    "                            cx,cy,w,h,theta = fit_rotated_ellipse_ransac(con.reshape(-1,2))\n",
    "                            #size_el = ellipse_circumference(w,h)\n",
    "\n",
    "                            # if size_el > min_thresh and size_el < max_thresh:\n",
    "                            \n",
    "                            #xcoordinates.append(cx)\n",
    "                            #ycoordinates.append(cy)\n",
    "                            cv2.ellipse(inf_img,(int(cx),int(cy)),(int(w),int(h)),theta*180.0/np.pi,0.0,360.0,(0,255,255),1)\n",
    "                            inf_img = cv2.drawMarker(inf_img, (int(cx),int(cy)),(0, 255, 255),cv2.MARKER_CROSS,2,1)\n",
    "                            #else: cx,cy,w,h,theta = 0.0,0.0,0.0,0.0,0.0\n",
    "                            \n",
    "                        except Exception as e: pass\n",
    "            \n",
    "        return inf_img,[cx,cy,w,h,theta]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_text(frame, text_lines, position):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 0.5\n",
    "    font_thickness = 1\n",
    "    color = (255, 255, 255)  # White color in BGR\n",
    "    \n",
    "    for i, line in enumerate(text_lines):\n",
    "        y_offset = i * 20  # Adjust vertical offset\n",
    "        cv2.putText(frame, line, (position[0], position[1] + y_offset), font, font_scale, color, font_thickness, cv2.LINE_AA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate distance between two points\n",
    "def distance(point1, point2):\n",
    "    return np.sqrt((point2[0] - point1[0])**2 + (point2[1] - point1[1])**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_velocity(object_data, prev_object_data, frame_rate):\n",
    "  \"\"\"\n",
    "  This function calculates the velocity of an object in pixels per frame.\n",
    "\n",
    "  Args:\n",
    "      object_data: A dictionary containing the current object data (x, y, width, height, angle).\n",
    "      prev_object_data: A dictionary containing the previous object data (from the previous frame).\n",
    "      frame_rate: The frame rate of the video.\n",
    "\n",
    "  Returns:\n",
    "      A dictionary containing the velocity in x and y directions (vx, vy) in pixels per frame.\n",
    "  \"\"\"\n",
    "  # Check if previous data is available\n",
    "  if not prev_object_data:\n",
    "    return {\"vx\": 0, \"vy\": 0}\n",
    "\n",
    "  center_x = int(object_data[0] + object_data[2] / 2)\n",
    "  center_y = int(object_data[1] + object_data[3] / 2)\n",
    "  prev_center_x = int(prev_object_data[0] + prev_object_data[2] / 2)\n",
    "  prev_center_y = int(prev_object_data[1] + prev_object_data[3] / 2)\n",
    "\n",
    "  # Calculate velocity in x and y directions (pixels per frame)\n",
    "  vx = (center_x - prev_center_x) / frame_rate\n",
    "  vy = (center_y - prev_center_y) / frame_rate\n",
    "\n",
    "  return {\"vx\": vx, \"vy\": vy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_object_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_velocity_arrow(frame, object_data, velocity, scale=10):\n",
    "  \"\"\"\n",
    "  This function draws an arrow on a frame to represent the object's velocity.\n",
    "\n",
    "  Args:\n",
    "      frame: The frame image from the video.\n",
    "      object_data: A dictionary containing object data (x, y, width, height, angle).\n",
    "      velocity: A dictionary containing velocity data (vx, vy) in pixels per frame.\n",
    "      scale: A factor to scale the arrow length for better visualization (optional).\n",
    "  \"\"\"\n",
    "  if object_data and velocity:\n",
    "    # Calculate arrow end point based on object center and scaled velocity\n",
    "    arrow_x = int(object_data[0] + velocity[\"vx\"] * scale)\n",
    "    arrow_y = int(object_data[1] + velocity[\"vy\"] * scale)\n",
    "    end_point = (arrow_x, arrow_y)\n",
    "\n",
    "\n",
    "    # Draw arrow line using cv2.arrowedLine\n",
    "    cv2.arrowedLine(frame, (int(object_data[0]), int(object_data[1])), end_point,\n",
    "                    (0, 0, 255), 2)  # Color: Blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_circle_around_ellipse(image, x, y, w, h,  circle_radius):\n",
    "    # Calculate the center of the ellipse\n",
    "    center_x = int(x + w / 2)\n",
    "    center_y = int(y + h / 2)\n",
    "\n",
    "    # Draw the circle around the ellipse center\n",
    "    cv2.circle(image, (center_x, center_y), circle_radius, (0, 255, 0), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "circle_center = (-1, -1)\n",
    "radius = 10\n",
    "def draw_circle(event, x, y, flags, param):\n",
    "    global circle_center, radius\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # Update circle center\n",
    "        circle_center = (x, y)\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and flags == cv2.EVENT_FLAG_LBUTTON:\n",
    "        # Update radius as the distance between the current position and the center\n",
    "        radius = max(1, int(((x - circle_center[0])**2 + (y - circle_center[1])**2)**0.5))\n",
    "        # Draw the circle and the line on the image\n",
    "        image = param.copy()\n",
    "        cv2.circle(image, circle_center, radius, (0, 255, 0), 2)\n",
    "        cv2.line(image, circle_center, (x, y), (0, 0, 255), 2)\n",
    "        cv2.imshow(\"Image\", image)\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        # Draw the final circle on the image\n",
    "        cv2.circle(param, circle_center, radius, (0, 255, 0), 2)\n",
    "        # Reset circle_center and radius\n",
    "        circle_center = (-1, -1)\n",
    "        radius = 10\n",
    "image = cv2.imread(\"frame_2.jpg\")  # Replace \"your_image_path.jpg\" with the path to your image\n",
    "\n",
    "\n",
    "# Create a window and bind the mouse callback function to it\n",
    "cv2.namedWindow(\"Image\")\n",
    "cv2.setMouseCallback(\"Image\", draw_circle, param=image)\n",
    "\n",
    "while True:\n",
    "    # Display the image\n",
    "    cv2.imshow(\"Image\", image)\n",
    "\n",
    "    # Check for key press\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\"):  # Press 'q' to quit\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting error = 0.000\n",
      "66.97404877437832 116.99331320564012 6.4454795878976086 11.829445893333133 0.1697630020921092\n",
      "fitting error = -0.000\n",
      "98.12479090510932 126.92954054648139 15.082923174472985 14.475756357842904 -0.2877188460896965\n",
      "fitting error = 0.000\n",
      "97.21035393145272 124.31881351901389 15.685497873581314 12.774742597759156 -0.3126110644509016\n",
      "fitting error = 0.000\n",
      "97.7052501020399 126.14576108557084 15.472146088665998 15.025269048859714 -0.33317085823026255\n",
      "fitting error = 0.000\n",
      "97.40785693940306 125.65936730712517 15.62625865744307 15.033594261971196 -0.10659292940657072\n",
      "fitting error = 0.000\n",
      "97.98349419210331 125.20324075604407 16.82139097809701 13.992386915406522 -0.061667369532889496\n",
      "fitting error = 0.000\n",
      "70.88115508191662 127.21292271607192 8.757779405274409 10.130282442616737 -0.04857881247044875\n",
      "fitting error = 0.000\n",
      "71.41265123159204 127.40114202375857 14.517641109816314 11.507159005637284 0.3169404720862618\n",
      "fitting error = 0.000\n",
      "68.01829217547964 110.33398143552138 12.180570681251828 14.541435027657942 -0.4107723975645129\n",
      "fitting error = 0.000\n",
      "67.56892329234346 110.97107742259783 13.48614351917439 15.264569714658016 -0.028687435138097746\n",
      "fitting error = 0.000\n",
      "67.16827196018863 111.66844622902688 14.037882417608246 15.798367747230648 0.16836681846711235\n",
      "fitting error = -0.000\n",
      "67.52885393737914 111.3228514983517 13.961314632286454 15.583749608464686 0.20580345026602864\n",
      "fitting error = 0.000\n",
      "67.47014796837043 111.77739177392665 13.78228585621632 15.874832040392695 0.03857512467627502\n",
      "fitting error = -0.000\n",
      "67.29112712318653 110.94588844770735 14.00216519522123 15.346687076311726 0.2420548876432615\n",
      "fitting error = -0.000\n",
      "66.78794557803627 111.58225915450684 13.577070975481083 15.880586497107767 0.2950223708302747\n",
      "fitting error = 0.000\n",
      "66.77564810958047 112.08291619992768 13.698734910673691 15.568697620657115 0.06190589014759796\n",
      "fitting error = -0.000\n",
      "66.89753567921049 112.17530186736319 13.824651796951153 15.67263576673985 0.07828262457532138\n",
      "fitting error = 0.000\n",
      "66.95544416984713 112.11175523885812 13.560790275920688 15.62944395063439 0.08214439437390274\n",
      "fitting error = -0.000\n",
      "66.72188846616888 112.19437510960502 13.928709530307703 15.578259851815604 0.1930712240229226\n",
      "fitting error = -0.000\n",
      "66.74719995967335 112.09731811621354 13.830943224461235 15.511418297231723 0.09595436454377042\n",
      "fitting error = -0.000\n",
      "66.74824872750438 112.06188939036367 13.906189613409007 15.332221994375354 0.2539282108511066\n",
      "fitting error = 0.000\n",
      "66.78340613883951 112.12323405924934 13.918794396932737 15.6465691799621 0.1788892756044073\n",
      "fitting error = -0.000\n",
      "67.05671183435112 112.10808889435808 13.810603586597907 16.240728421342766 0.014001404298445099\n",
      "fitting error = -0.000\n",
      "67.14490841992344 112.0552329704878 13.87930185981048 16.297373525844932 0.008138962663668002\n",
      "fitting error = 0.000\n",
      "67.0282183771034 111.74835034765262 14.132863229875037 16.013077293621897 0.2117048029445903\n",
      "fitting error = -0.000\n",
      "67.10657603450498 111.97241684327223 14.317707770707377 16.361074217136238 0.03370740693888062\n",
      "fitting error = 0.000\n",
      "67.25591748745161 111.72629859083962 14.157631656125368 16.731566990937807 0.08468775254121781\n",
      "fitting error = 0.000\n",
      "67.3469271883782 111.54536743395654 14.221404535613841 16.76917863499118 0.05015925282007809\n",
      "fitting error = 0.000\n",
      "71.5363207711644 110.73138944300753 12.530899843346308 16.064656736032997 -0.012550563516970788\n",
      "fitting error = 0.000\n",
      "85.81877578123759 110.17858973404081 16.745964964763942 16.040506786302327 -0.4057738767763073\n",
      "fitting error = 0.000\n",
      "85.75758896296769 110.59249200914755 16.77513258800858 15.941125881537372 0.007447241590414345\n",
      "fitting error = 0.000\n",
      "86.07162556207933 110.71093345724564 17.02149110459968 16.330451914442786 0.3070238231988351\n",
      "fitting error = -0.000\n",
      "85.99202405294827 110.65149788205763 17.164821830281117 16.356457006220108 0.31671246724832675\n",
      "fitting error = 0.000\n",
      "86.0362823354421 111.06578463044723 17.096796702500882 16.86556619147185 0.5820000569463709\n",
      "fitting error = -0.000\n",
      "85.99323669177262 111.07660997696209 17.110759911630435 16.81459948942012 0.728582951998228\n",
      "fitting error = 0.000\n",
      "86.19145639872603 110.72123746696754 17.130671414349575 16.707739179341605 0.1422549427892681\n",
      "fitting error = -0.000\n",
      "89.99297389711613 109.94921943639919 16.303362692316 17.29551985762468 -0.05249978668494598\n",
      "fitting error = 0.000\n",
      "90.02297722942949 109.86955097059214 17.22396220511409 17.035123651282014 -0.734190990252509\n",
      "fitting error = 0.000\n",
      "90.186139347244 110.01517138111448 17.37466000896736 16.880454505814768 0.7113712733057489\n",
      "fitting error = 0.000\n",
      "90.3365529636743 109.74014568595517 17.288886571257812 16.881508071901713 0.36468816110149366\n",
      "fitting error = 0.000\n",
      "90.29081152309864 109.24535792653657 17.255514928279034 17.128696660732793 -0.7552394849302994\n",
      "fitting error = 0.000\n",
      "90.24798948508123 109.13048567324472 17.9972394037708 16.946506700473456 0.10749600605395762\n",
      "fitting error = -0.000\n",
      "89.55624947022069 113.57697957064882 17.63375463449842 10.791463891662318 0.2522345086569811\n",
      "fitting error = -0.000\n",
      "91.21608736875255 110.84668063082808 18.1793260946458 15.946559811747612 0.3020490941637944\n",
      "fitting error = 0.000\n",
      "90.88894117429534 110.94398566261727 18.361630698756283 16.646534975068647 0.1333737411286567\n",
      "fitting error = 0.000\n",
      "90.15581733351667 111.31065983014074 18.38373043566538 17.010535659436535 0.39978807576653075\n",
      "fitting error = 0.000\n",
      "89.8731140899696 111.69437796589548 18.159438059233693 17.129247418498796 0.5702049585063873\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('./11.avi')\n",
    "\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "while(cap.isOpened()):\n",
    "  # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    \n",
    "    if ret == True:\n",
    "        frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        out,cnt = fitPupil(frame,circ_thresh=.5,thresh_val=45)\n",
    "        height, width, _ = out.shape\n",
    "        \n",
    "        \n",
    "\n",
    "        if all(element != 0 for element in cnt):\n",
    "            x,y,w,h,angle = cnt\n",
    "            \n",
    "            \n",
    "            \n",
    "            # You can adjust the position as needed\n",
    "            object_data = cnt\n",
    "\n",
    "            velocity = calculate_velocity(object_data, prev_object_data, frame_rate)\n",
    "            \n",
    "            \n",
    "\n",
    "           \n",
    "            text_lines = [f'x: {cnt[0]:.2f}', f'y: {cnt[1]:.2f}', f'w: {cnt[2]:.2f}', f'h: {cnt[3]:.2f}',\n",
    "                           f'angle: {cnt[4]:.2f}',f'vx: {velocity[\"vx\"]:.2f}',\n",
    "                           f'vy: {velocity[\"vy\"]:.2f}'\n",
    "                           ]\n",
    "            \n",
    "            if velocity:\n",
    "              #pass\n",
    "              draw_velocity_arrow(out,object_data,velocity)\n",
    "\n",
    "            resized_out = cv2.resize(out, (width*2,height*2))\n",
    "            \n",
    "            center_x = int(x/ 2)\n",
    "            center_y = int(y / 2)\n",
    "\n",
    "            \n",
    "\n",
    "            # Draw circle in the middle\n",
    "            cv2.circle(resized_out, (int(x)+100, int(y)+100), 160, (0, 255, 0), 1)\n",
    "            #draw_circle_around_ellipse(resized_out, center_x , center_y, cnt[2], cnt[3], 100)\n",
    "            draw_text(resized_out, text_lines, (10, 30))\n",
    "            cv2.imshow(\"Frame\",resized_out)\n",
    "            print(x,y,w,h,angle)\n",
    "           \n",
    "            \n",
    "            prev_object_data = object_data\n",
    "            if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                break   \n",
    "    # Break the loop\n",
    "    else: break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mrotate(frame, cv2\u001b[38;5;241m.\u001b[39mROTATE_90_COUNTERCLOCKWISE)\n\u001b[1;32m---> 12\u001b[0m     \u001b[43mgaze_tracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     14\u001b[0m     eyes \u001b[38;5;241m=\u001b[39m eye_cascade\u001b[38;5;241m.\u001b[39mdetectMultiScale(gray)\n",
      "File \u001b[1;32me:\\Last Version\\OfflineTracker\\gaze_tracker.py:25\u001b[0m, in \u001b[0;36mGazeTracker.update\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, frame):\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye_tracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_eye \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meye_tracker\u001b[38;5;241m.\u001b[39mleft_eye()\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_eye \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meye_tracker\u001b[38;5;241m.\u001b[39mright_eye()\n",
      "File \u001b[1;32me:\\Last Version\\OfflineTracker\\eye_tracker.py:48\u001b[0m, in \u001b[0;36mEyeTracker.update\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, frame):\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe \u001b[38;5;241m=\u001b[39m frame\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_analyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Last Version\\OfflineTracker\\eye_tracker.py:54\u001b[0m, in \u001b[0;36mEyeTracker._analyze\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_analyze\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_face\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_eyes()\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_eye_detected:\n",
      "File \u001b[1;32me:\\Last Version\\OfflineTracker\\eye_tracker.py:175\u001b[0m, in \u001b[0;36mEyeTracker._extract_face\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    171\u001b[0m         frame_gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_gray, (\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m7\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m#        frame_gray = cv2.medianBlur(frame_gray, 7)\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m#        faces = self.face_cascade.detectMultiScale(frame_gray) \u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m         faces \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface_cascade\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectMultiScale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_gray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m    177\u001b[0m         \u001b[38;5;66;03m# detect the best face on the image based on ROI size\u001b[39;00m\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(faces) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('./11.avi')\n",
    "screen.clean()\n",
    "screen.show()\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "while(cap.isOpened()):\n",
    "  # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    \n",
    "    if ret == True:\n",
    "        frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        eyes = eye_cascade.detectMultiScale(gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "          cv2.rectangle(gray,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "          break\n",
    "        cv2.imshow(\"Eyes\",gray)\n",
    "        if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaze direction: Right\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_gaze_direction(x, y, w, h, angle, image_width, image_height):\n",
    "    # Convert angle to radians\n",
    "    angle_rad = np.deg2rad(angle)\n",
    "    \n",
    "    # Calculate the center of the ellipse\n",
    "    center_x = x + w / 2\n",
    "    center_y = y + h / 2\n",
    "    \n",
    "    # Calculate the direction vector based on angle\n",
    "    direction_vector = np.array([np.cos(angle_rad), np.sin(angle_rad)])\n",
    "    \n",
    "    # Normalize the direction vector\n",
    "    direction_vector /= np.linalg.norm(direction_vector)\n",
    "    \n",
    "    # Calculate the dot product of direction vector and horizontal/vertical axis\n",
    "    horizontal_dot = np.dot(direction_vector, [1, 0])  # Horizontal axis\n",
    "    vertical_dot = np.dot(direction_vector, [0, 1])    # Vertical axis\n",
    "    \n",
    "    # Determine the direction based on dot products\n",
    "    if abs(horizontal_dot) > abs(vertical_dot):\n",
    "        if horizontal_dot > 0:\n",
    "            return \"Right\"\n",
    "        else:\n",
    "            return \"Left\"\n",
    "    else:\n",
    "        if vertical_dot > 0:\n",
    "            return \"Down\"\n",
    "        else:\n",
    "            return \"Up\"\n",
    "\n",
    "# Example usage\n",
    "x = 100  # Example ellipse x-coordinate\n",
    "y = 150  # Example ellipse y-coordinate\n",
    "w = 50   # Example ellipse width\n",
    "h = 30   # Example ellipse height\n",
    "angle = 30  # Example ellipse angle\n",
    "image_width = 640  # Example image width\n",
    "image_height = 480  # Example image height\n",
    "\n",
    "direction = get_gaze_direction(x, y, w, h, angle, image_width, image_height)\n",
    "print(\"Gaze direction:\", direction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
